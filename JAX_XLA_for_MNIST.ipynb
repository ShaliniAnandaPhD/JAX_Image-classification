{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiTDpGuJmRBjHBeOIj5KhG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaliniAnandaPhD/JAX_Image-classification/blob/main/JAX_XLA_for_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detailed Description of Learnings from the JAX/XLA Project\n",
        "\n",
        "#### Introduction to JAX/XLA\n",
        "The exploration of JAX/XLA as part of this project offered valuable insights into high-performance numerical computing and machine learning. JAX, a library developed by Google, extends the capabilities of Python by providing an advanced array manipulation interface. Its synergy with XLA (Accelerated Linear Algebra) enables optimized computation, especially beneficial for tasks involving large-scale numerical operations.\n",
        "\n",
        "#### Key Learnings\n",
        "\n",
        "1. **Understanding of JAX's Core Features**:\n",
        "    - **Automatic Differentiation**: JAX's ability to automatically compute derivatives and gradients is a cornerstone for machine learning, significantly easing the implementation of training loops for neural networks.\n",
        "    - **Just-In-Time Compilation**: The JIT compiler in JAX transforms Python functions into highly efficient machine code, substantially boosting performance. This aspect is particularly crucial when handling large datasets or complex computations.\n",
        "    - **Vectorization and Parallelism**: JAX's `vmap` and `pmap` functions facilitate easy vectorization of code and parallel execution across multiple devices, a prelude to understanding more complex distributed computing concepts.\n",
        "\n",
        "2. **Application in Neural Network Training**:\n",
        "    - Developing a neural network for the MNIST dataset using JAX demonstrated its efficacy in handling typical machine learning workflows.\n",
        "    - The project emphasized the importance of efficient data handling, model definition, and optimization in a Pythonic way, enhanced by JAX's powerful features.\n",
        "\n",
        "3. **Experimentation with TPUs in Google Colab**:\n",
        "    - The use of TPUs (Tensor Processing Units) in Colab provided practical experience with parallel computations, leveraging JAX’s compatibility with TPUs for accelerated performance.\n",
        "\n",
        "4. **Insights into Multi-Host Training**:\n",
        "    - While not directly implemented, the project offered theoretical insights into scaling JAX applications for multi-host environments. This is critical for understanding real-world applications where distributed computing is necessary.\n",
        "\n",
        "#### Importance of Using JAX/XLA over Python\n",
        "\n",
        "1. **Performance Optimization**:\n",
        "    - JAX/XLA significantly outperforms standard Python, especially for numerical computations, due to JIT compilation and efficient memory management.\n",
        "\n",
        "2. **Ease of Scaling**:\n",
        "    - JAX simplifies the transition from single-device to multi-device or multi-host computations, an area where Python alone falls short.\n",
        "\n",
        "3. **Advanced Numerical Capabilities**:\n",
        "    - JAX extends Python's numerical capabilities with advanced features like automatic differentiation and GPU/TPU support, which are essential for modern machine learning and data analysis tasks.\n",
        "\n",
        "#### Purpose and Scope\n",
        "\n",
        "- **Learning and Exploration**: The project was primarily educational, aimed at understanding JAX/XLA's capabilities and its application in machine learning and parallel computing.\n",
        "- **Foundation for Advanced Applications**: While the focus was on learning and experimentation, the insights gained lay the groundwork for tackling more complex, real-world tasks in high-performance computing and AI research.\n",
        "\n",
        "#### Conclusion\n",
        "\n",
        "The exploration of JAX/XLA proved to be an enriching experience, highlighting the library's potential in elevating Python's capabilities to meet the demands of modern computational tasks. The project underscored the importance of JAX/XLA in the landscape of numerical computing and machine learning, providing a solid foundation for further exploration and application in more complex scenarios."
      ],
      "metadata": {
        "id": "u4DpmQmJdnm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Installing dependancies*"
      ],
      "metadata": {
        "id": "GfeO5G3nnEpg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE9qV2ILXhC1",
        "outputId": "308b21d0-52bb-4d5e-ec29-738a71c332bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.20)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.20+cuda11.cudnn86)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax) (1.11.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed keras-2.15.0 tensorboard-2.15.1 tensorflow-2.15.0 tensorflow-estimator-2.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade jax jaxlib tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Load and Preprocess the Dataset*"
      ],
      "metadata": {
        "id": "t_be7SXTnWpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the images to [0, 1]\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Display the first 5 images from the training dataset\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.title(f\"Label: {train_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "_BW6nq96X63P",
        "outputId": "cd5615e9-6957-42c4-b9ca-fe4433bc7644"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flax\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oayMSCBRYwh4",
        "outputId": "60ce14de-bbad-4be6-dae1-f75ffb00d263"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.7.5)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from flax) (1.23.5)\n",
            "Requirement already satisfied: jax>=0.4.19 in /usr/local/lib/python3.10/dist-packages (from flax) (0.4.20)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.0.7)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.7)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax) (0.4.2)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax) (1.11.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.1.7)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.4.20+cuda11.cudnn86)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.5.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.5.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (3.20.3)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax) (0.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Define the Model\n",
        "Next, we'll define a simple neural network model using JAX. For simplicity, let's create a two-layer fully connected network.\n",
        "\n",
        "Step 3.1: Define the Neural Network"
      ],
      "metadata": {
        "id": "srELVmiHoFvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import linen as nn\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = nn.Dense(128)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(10)(x)\n",
        "        return nn.softmax(x)\n",
        "\n",
        "# Initialize the network\n",
        "key = jax.random.PRNGKey(1)\n",
        "model = SimpleNN()\n",
        "dummy_input = jnp.zeros((1, 28*28))  # Example input\n",
        "params = model.init(key, dummy_input)\n",
        "\n"
      ],
      "metadata": {
        "id": "M1xLZbjjX-Qa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade jax jaxlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xblt9kokZN_c",
        "outputId": "23845b48-53ab-4f8b-e6c7-de5aedc4274e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.20)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.20+cuda11.cudnn86)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax) (1.11.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optax\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1zi3IHnZSvx",
        "outputId": "fb68bc1b-f015-46ac-862c-9689dc3ec964"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax) (0.1.7)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.10/dist-packages (from optax) (0.4.20)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax) (0.4.20+cuda11.cudnn86)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from optax) (1.23.5)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax) (4.5.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.1.55->optax) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.1.55->optax) (1.11.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Training Loop\n",
        "Now, we'll implement a training loop that includes forward pass, loss calculation, and backpropagation.\n",
        "\n",
        "Define Loss Function and Update Step"
      ],
      "metadata": {
        "id": "-7FootbXoP6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optax.sgd(learning_rate=0.01)\n",
        "\n",
        "# Initialize optimizer state\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "# Update function\n",
        "def update(params, opt_state, grads):\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    new_params = optax.apply_updates(params, updates)\n",
        "    return new_params, opt_state\n"
      ],
      "metadata": {
        "id": "WK56n5VdZXM1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "ZKt4Ldf9oZSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming train_images and train_labels are your training data and labels\n",
        "batch_size = 128\n",
        "num_batches = len(train_images) // batch_size\n",
        "\n",
        "# Create batches\n",
        "data_batches = [(train_images[i:i+batch_size].reshape(-1, 28*28),\n",
        "                 train_labels[i:i+batch_size])\n",
        "                for i in range(0, len(train_images), batch_size)]\n"
      ],
      "metadata": {
        "id": "duSDekeMZ8xq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from jax import grad, value_and_grad\n",
        "\n",
        "def loss_fn(params, batch):\n",
        "    inputs, targets = batch\n",
        "    # Assume `model` is your neural network model\n",
        "    preds = model.apply(params, inputs)\n",
        "    # Using cross-entropy loss\n",
        "    return -jnp.mean(jnp.sum(targets * jnp.log(preds), axis=1))\n"
      ],
      "metadata": {
        "id": "FI9xeuV8aQL3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Hot Encode the Labels: If your labels are not one-hot encoded, you should convert them to a one-hot format to match the shape of the predictions. JAX provides a utility function for this."
      ],
      "metadata": {
        "id": "8q28mSNgoj40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax.nn import one_hot\n",
        "\n",
        "def one_hot_labels(labels, num_classes=10):\n",
        "    return one_hot(labels, num_classes)\n"
      ],
      "metadata": {
        "id": "mnZF0Ojpak8_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure your loss function correctly handles the shapes. Here's an updated version assuming you're working with one-hot encoded labels and a softmax output from your model:"
      ],
      "metadata": {
        "id": "4I1Vi1V1ow8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(params, batch):\n",
        "    inputs, targets = batch\n",
        "    preds = model.apply(params, inputs)\n",
        "    targets_one_hot = one_hot_labels(targets)\n",
        "    return -jnp.mean(jnp.sum(targets_one_hot * jnp.log(preds), axis=1))\n"
      ],
      "metadata": {
        "id": "61_gMHW1apM8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure that the labels are properly formatted before they are passed to the loss function.\n"
      ],
      "metadata": {
        "id": "upWb81lro47a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(params, batch):\n",
        "    inputs, targets = batch\n",
        "    preds = model.apply(params, inputs)\n",
        "\n",
        "    # Reshape predictions if necessary\n",
        "    preds = preds.reshape(preds.shape[:2])  # Adjust this based on your model's output\n",
        "\n",
        "    return -jnp.mean(jnp.sum(targets * jnp.log(preds), axis=1))\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, targets in data_batches:\n",
        "        # Convert targets to one-hot encoding\n",
        "        targets_one_hot = one_hot_labels(targets)\n",
        "        batch = (inputs, targets_one_hot)\n",
        "\n",
        "        # Compute loss and gradients\n",
        "        loss, grads = value_and_grad(loss_fn)(params, batch)\n",
        "        params, opt_state = update(params, opt_state, grads)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} completed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfQQ13rYbAiV",
        "outputId": "64f52fc9-91ba-4503-8cdc-e821a052d7f9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed\n",
            "Epoch 2 completed\n",
            "Epoch 3 completed\n",
            "Epoch 4 completed\n",
            "Epoch 5 completed\n",
            "Epoch 6 completed\n",
            "Epoch 7 completed\n",
            "Epoch 8 completed\n",
            "Epoch 9 completed\n",
            "Epoch 10 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation\n",
        "\n",
        "The evaluation step involves running the trained model on a separate test dataset and comparing its predictions against the true labels. Here's a basic way to do it:\n",
        "\n",
        "Load and Preprocess the Test Data: Ensure that the test data is preprocessed in the same way as the training data.\n",
        "\n",
        "Define the Accuracy Function: This function will compare the predicted labels with the true labels to calculate the accuracy.\n",
        "\n",
        "Run the Model on Test Data: Use the trained model to make predictions on the test data.\n"
      ],
      "metadata": {
        "id": "5H5D_ldpnn7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(params, data_loader):\n",
        "    # Counts the number of correct predictions\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in data_loader:\n",
        "        predicted_probs = model.apply(params, inputs)\n",
        "        predicted_labels = jnp.argmax(predicted_probs, axis=1)\n",
        "        correct += jnp.sum(predicted_labels == targets)\n",
        "        total += len(targets)\n",
        "    return correct / total\n",
        "\n",
        "# Create a test data loader\n",
        "test_data_batches = [(test_images[i:i+batch_size].reshape(-1, 28*28),\n",
        "                      test_labels[i:i+batch_size])\n",
        "                     for i in range(0, len(test_images), batch_size)]\n",
        "\n",
        "# Calculate accuracy on test data\n",
        "test_accuracy = accuracy(params, test_data_batches)\n",
        "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ITLB9Gb_oY",
        "outputId": "c7ea7143-0da7-4912-e153-004d7fb7fb2c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 92.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_35ZY7PcpFy",
        "outputId": "15825e5c-9891-4dcf-c28a-bd2ba7f506d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
            "Requirement already satisfied: jax[tpu] in /usr/local/lib/python3.10/dist-packages (0.3.25)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from jax[tpu]) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[tpu]) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax[tpu]) (1.11.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from jax[tpu]) (4.5.0)\n",
            "Requirement already satisfied: jaxlib==0.3.25 in /usr/local/lib/python3.10/dist-packages (from jax[tpu]) (0.3.25)\n",
            "Collecting libtpu-nightly==0.1.dev20221109 (from jax[tpu])\n",
            "  Downloading https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/wheels/libtpu-nightly/libtpu_nightly-0.1.dev20221109-py3-none-any.whl (181.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from jax[tpu]) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->jax[tpu]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->jax[tpu]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->jax[tpu]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->jax[tpu]) (2023.7.22)\n",
            "Installing collected packages: libtpu-nightly\n",
            "Successfully installed libtpu-nightly-0.1.dev20221109\n"
          ]
        }
      ]
    }
  ]
}